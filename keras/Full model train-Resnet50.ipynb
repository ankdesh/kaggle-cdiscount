{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "from keras.preprocessing.image import Iterator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "import threading\n",
    "lock = threading.Lock()\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from BsonIterator import BSONIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankdesh/virtualenvs/cdiscount-py2.7/local/lib/python2.7/site-packages/numpy/lib/arraysetops.py:463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5570369 images belonging to 5270 classes.\n",
      "Found 614245 images belonging to 5270 classes.\n"
     ]
    }
   ],
   "source": [
    "METADATA_DIR = 'metadata'\n",
    "DATA_DIR = '../../dataset'\n",
    "\n",
    "train_offsets_df = pd.read_csv(os.path.join(METADATA_DIR,\"train_offsets.csv\"), index_col=0)\n",
    "train_images_df = pd.read_csv(os.path.join(METADATA_DIR,\"RandomSplit_Train_0.5_0.1.csv\"), index_col=0)\n",
    "val_images_df = pd.read_csv(os.path.join(METADATA_DIR,\"RandomSplit_Val_0.5_0.1.csv\"), index_col=0)\n",
    "\n",
    "num_classes = 5270\n",
    "num_train_images = len(train_images_df)\n",
    "num_val_images = len(val_images_df)\n",
    "batch_size = 32\n",
    "\n",
    "# Create a generator for training and a generator for validation.\n",
    "# Tip: use ImageDataGenerator for data augmentation and preprocessing.\n",
    "assert os.path.exists(os.path.join(DATA_DIR, 'train.bson'))\n",
    "train_bson_file = open(os.path.join(DATA_DIR, 'train.bson'), \"rb\")\n",
    "train_datagen = ImageDataGenerator()\n",
    "train_gen = BSONIterator(train_bson_file, train_images_df, train_offsets_df,\n",
    "                         num_classes, train_datagen, lock, target_size = (224,224),\n",
    "                         batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "val_gen = BSONIterator(train_bson_file, val_images_df, train_offsets_df,\n",
    "                       num_classes, val_datagen, lock, target_size = (224,224),\n",
    "                       batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Save model Dir\n",
    "MODEL_DIR = 'saved_models'\n",
    "\n",
    "# Checkpointer \n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/Resnet50.{epoch:02d}-{acc:.2f}-{val_acc:.2f}_RandomSplit_Train_0.5_0.1.h5', verbose=1)\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer \n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions, name= 'Resenet50')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:175]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[175:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "from keras.optimizers import Adam\n",
    "opt = Adam(lr=0.0001)\n",
    "model.compile(optimizer=opt,\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "tb = TensorBoard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "174073/174074 [============================>.] - ETA: 0s - loss: 3.2849 - acc: 0.4330Epoch 00000: saving model to saved_models/Resnet50.00-3.28-3.25_RandomSplit_Train_0.5_0.1.h5\n",
      "174074/174074 [==============================] - ETA: 0s - loss: 3.2849 - acc: 0.4330 - val_loss: 3.2520 - val_acc: 0.4384\n",
      "Epoch 2/2\n",
      "174073/174074 [============================>.] - ETA: 0s - loss: 3.2409 - acc: 0.4374Epoch 00001: saving model to saved_models/Resnet50.01-3.24-3.22_RandomSplit_Train_0.5_0.1.h5\n",
      "174074/174074 [==============================] - ETA: 0s - loss: 3.2409 - acc: 0.4374 - val_loss: 3.2185 - val_acc: 0.4413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5e70ff14d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "model.fit_generator(train_gen,\n",
    "                    steps_per_epoch = num_train_images // batch_size,\n",
    "                    epochs = num_epochs,\n",
    "                    validation_data = val_gen,\n",
    "                    validation_steps = num_val_images // batch_size,\n",
    "                    workers = 4, callbacks=[checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'input_1')\n",
      "(1, 'conv1')\n",
      "(2, 'bn_conv1')\n",
      "(3, 'activation_1')\n",
      "(4, 'max_pooling2d_1')\n",
      "(5, 'res2a_branch2a')\n",
      "(6, 'bn2a_branch2a')\n",
      "(7, 'activation_2')\n",
      "(8, 'res2a_branch2b')\n",
      "(9, 'bn2a_branch2b')\n",
      "(10, 'activation_3')\n",
      "(11, 'res2a_branch2c')\n",
      "(12, 'res2a_branch1')\n",
      "(13, 'bn2a_branch2c')\n",
      "(14, 'bn2a_branch1')\n",
      "(15, 'add_1')\n",
      "(16, 'activation_4')\n",
      "(17, 'res2b_branch2a')\n",
      "(18, 'bn2b_branch2a')\n",
      "(19, 'activation_5')\n",
      "(20, 'res2b_branch2b')\n",
      "(21, 'bn2b_branch2b')\n",
      "(22, 'activation_6')\n",
      "(23, 'res2b_branch2c')\n",
      "(24, 'bn2b_branch2c')\n",
      "(25, 'add_2')\n",
      "(26, 'activation_7')\n",
      "(27, 'res2c_branch2a')\n",
      "(28, 'bn2c_branch2a')\n",
      "(29, 'activation_8')\n",
      "(30, 'res2c_branch2b')\n",
      "(31, 'bn2c_branch2b')\n",
      "(32, 'activation_9')\n",
      "(33, 'res2c_branch2c')\n",
      "(34, 'bn2c_branch2c')\n",
      "(35, 'add_3')\n",
      "(36, 'activation_10')\n",
      "(37, 'res3a_branch2a')\n",
      "(38, 'bn3a_branch2a')\n",
      "(39, 'activation_11')\n",
      "(40, 'res3a_branch2b')\n",
      "(41, 'bn3a_branch2b')\n",
      "(42, 'activation_12')\n",
      "(43, 'res3a_branch2c')\n",
      "(44, 'res3a_branch1')\n",
      "(45, 'bn3a_branch2c')\n",
      "(46, 'bn3a_branch1')\n",
      "(47, 'add_4')\n",
      "(48, 'activation_13')\n",
      "(49, 'res3b_branch2a')\n",
      "(50, 'bn3b_branch2a')\n",
      "(51, 'activation_14')\n",
      "(52, 'res3b_branch2b')\n",
      "(53, 'bn3b_branch2b')\n",
      "(54, 'activation_15')\n",
      "(55, 'res3b_branch2c')\n",
      "(56, 'bn3b_branch2c')\n",
      "(57, 'add_5')\n",
      "(58, 'activation_16')\n",
      "(59, 'res3c_branch2a')\n",
      "(60, 'bn3c_branch2a')\n",
      "(61, 'activation_17')\n",
      "(62, 'res3c_branch2b')\n",
      "(63, 'bn3c_branch2b')\n",
      "(64, 'activation_18')\n",
      "(65, 'res3c_branch2c')\n",
      "(66, 'bn3c_branch2c')\n",
      "(67, 'add_6')\n",
      "(68, 'activation_19')\n",
      "(69, 'res3d_branch2a')\n",
      "(70, 'bn3d_branch2a')\n",
      "(71, 'activation_20')\n",
      "(72, 'res3d_branch2b')\n",
      "(73, 'bn3d_branch2b')\n",
      "(74, 'activation_21')\n",
      "(75, 'res3d_branch2c')\n",
      "(76, 'bn3d_branch2c')\n",
      "(77, 'add_7')\n",
      "(78, 'activation_22')\n",
      "(79, 'res4a_branch2a')\n",
      "(80, 'bn4a_branch2a')\n",
      "(81, 'activation_23')\n",
      "(82, 'res4a_branch2b')\n",
      "(83, 'bn4a_branch2b')\n",
      "(84, 'activation_24')\n",
      "(85, 'res4a_branch2c')\n",
      "(86, 'res4a_branch1')\n",
      "(87, 'bn4a_branch2c')\n",
      "(88, 'bn4a_branch1')\n",
      "(89, 'add_8')\n",
      "(90, 'activation_25')\n",
      "(91, 'res4b_branch2a')\n",
      "(92, 'bn4b_branch2a')\n",
      "(93, 'activation_26')\n",
      "(94, 'res4b_branch2b')\n",
      "(95, 'bn4b_branch2b')\n",
      "(96, 'activation_27')\n",
      "(97, 'res4b_branch2c')\n",
      "(98, 'bn4b_branch2c')\n",
      "(99, 'add_9')\n",
      "(100, 'activation_28')\n",
      "(101, 'res4c_branch2a')\n",
      "(102, 'bn4c_branch2a')\n",
      "(103, 'activation_29')\n",
      "(104, 'res4c_branch2b')\n",
      "(105, 'bn4c_branch2b')\n",
      "(106, 'activation_30')\n",
      "(107, 'res4c_branch2c')\n",
      "(108, 'bn4c_branch2c')\n",
      "(109, 'add_10')\n",
      "(110, 'activation_31')\n",
      "(111, 'res4d_branch2a')\n",
      "(112, 'bn4d_branch2a')\n",
      "(113, 'activation_32')\n",
      "(114, 'res4d_branch2b')\n",
      "(115, 'bn4d_branch2b')\n",
      "(116, 'activation_33')\n",
      "(117, 'res4d_branch2c')\n",
      "(118, 'bn4d_branch2c')\n",
      "(119, 'add_11')\n",
      "(120, 'activation_34')\n",
      "(121, 'res4e_branch2a')\n",
      "(122, 'bn4e_branch2a')\n",
      "(123, 'activation_35')\n",
      "(124, 'res4e_branch2b')\n",
      "(125, 'bn4e_branch2b')\n",
      "(126, 'activation_36')\n",
      "(127, 'res4e_branch2c')\n",
      "(128, 'bn4e_branch2c')\n",
      "(129, 'add_12')\n",
      "(130, 'activation_37')\n",
      "(131, 'res4f_branch2a')\n",
      "(132, 'bn4f_branch2a')\n",
      "(133, 'activation_38')\n",
      "(134, 'res4f_branch2b')\n",
      "(135, 'bn4f_branch2b')\n",
      "(136, 'activation_39')\n",
      "(137, 'res4f_branch2c')\n",
      "(138, 'bn4f_branch2c')\n",
      "(139, 'add_13')\n",
      "(140, 'activation_40')\n",
      "(141, 'res5a_branch2a')\n",
      "(142, 'bn5a_branch2a')\n",
      "(143, 'activation_41')\n",
      "(144, 'res5a_branch2b')\n",
      "(145, 'bn5a_branch2b')\n",
      "(146, 'activation_42')\n",
      "(147, 'res5a_branch2c')\n",
      "(148, 'res5a_branch1')\n",
      "(149, 'bn5a_branch2c')\n",
      "(150, 'bn5a_branch1')\n",
      "(151, 'add_14')\n",
      "(152, 'activation_43')\n",
      "(153, 'res5b_branch2a')\n",
      "(154, 'bn5b_branch2a')\n",
      "(155, 'activation_44')\n",
      "(156, 'res5b_branch2b')\n",
      "(157, 'bn5b_branch2b')\n",
      "(158, 'activation_45')\n",
      "(159, 'res5b_branch2c')\n",
      "(160, 'bn5b_branch2c')\n",
      "(161, 'add_15')\n",
      "(162, 'activation_46')\n",
      "(163, 'res5c_branch2a')\n",
      "(164, 'bn5c_branch2a')\n",
      "(165, 'activation_47')\n",
      "(166, 'res5c_branch2b')\n",
      "(167, 'bn5c_branch2b')\n",
      "(168, 'activation_48')\n",
      "(169, 'res5c_branch2c')\n",
      "(170, 'bn5c_branch2c')\n",
      "(171, 'add_16')\n",
      "(172, 'activation_49')\n",
      "(173, 'avg_pool')\n",
      "(174, 'global_average_pooling2d_1')\n",
      "(175, 'dense_1')\n",
      "(176, 'dense_2')\n",
      "(177, 'dense_3')\n"
     ]
    }
   ],
   "source": [
    "for i,layer in enumerate(model.layers):\n",
    "    print (i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
